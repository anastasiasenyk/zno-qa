{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLama API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from together import Together\n",
    "\n",
    "def get_response_llama(question):\n",
    "    client = Together(api_key=\"48b3165bc375864a7fa01a488f1a7e8200d93750eaff0fe1d070faaf293dd282\")\n",
    "    \n",
    "    instruction = \"Обери правильну відповідь і поверни одну із букв (А, Б, В, Г чи Д) без додаткових символів\\n\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo\",\n",
    "        messages=[\n",
    "            {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"{question}\\n{instruction}\"\n",
    "            }\n",
    "    ],\n",
    "        temperature=0.7,\n",
    "        top_p=0.7,\n",
    "        top_k=50,\n",
    "        repetition_penalty=1,\n",
    "        stop=[\"<|eot_id|>\",\"<|eom_id|>\"],\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "    # for token in response:\n",
    "    #     if hasattr(token, 'choices'):\n",
    "    #         print(token.choices[0].delta.content, end='', flush=True)\n",
    "    \n",
    "    return list(response)[0].choices[0].delta.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Г'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = get_response_llama(\"{\\\"question\\\": \\\"Конституцію України було ухвалено\\\", \\\"answers\\\": [{\\\"marker\\\": \\\"А\\\", \\\"text\\\": \\\"16 липня 1990 р.\\\"}, {\\\"marker\\\": \\\"Б\\\", \\\"text\\\": \\\"24 серпня 1991 р.\\\"}, {\\\"marker\\\": \\\"В\\\", \\\"text\\\": \\\"19 липня 1994 р.\\\"}, {\\\"marker\\\": \\\"Г\\\", \\\"text\\\": \\\"28 червня 1996 р.\\\"}], \\\"correct_answers\\\": [\\\"Г\\\"], \\\"subject\\\": \\\"history-of-ukraine\\\"}\\n\\n\")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mistral API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mistralai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mistralai import Mistral\n",
    "import os\n",
    "\n",
    "def get_response_mistralai(question):\n",
    "    api_key = \"VfYhdPWFvbdjGv5UKkh0pYJMMsesmdTi\"\n",
    "    model = \"mistral-large-latest\"\n",
    "\n",
    "    client = Mistral(api_key=api_key)\n",
    "\n",
    "    chat_response = client.chat.complete(\n",
    "        model= model,\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": question,\n",
    "            },\n",
    "        ]\n",
    "    )\n",
    "    return(chat_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Choosing the \"best\" French cheese can be subjective and depends on personal taste, as France offers a wide variety of exceptional cheeses. However, some French cheeses are world-renowned for their unique flavors and qualities. Here are a few notable ones:\\n\\n1. **Camembert de Normandie**: A soft, creamy cheese from the Normandy region, famous for its rich, buttery flavor and bloomy rind.\\n\\n2. **Brie de Meaux**: Often referred to as the \"King of Cheeses,\" this soft cheese from the Brie region is known for its creamy interior and delicate, edible rind.\\n\\n3. **Roquefort**: A classic blue cheese made from sheep\\'s milk, known for its strong, tangy flavor and distinctive blue veins.\\n\\n4. **Comté**: A hard cheese made from unpasteurized cow\\'s milk in the Franche-Comté region. It has a complex, nutty flavor that varies with age.\\n\\n5. **Reblochon**: A soft washed-rind and smear-ripened cheese from the Alps, known for its creamy texture and mild, nutty flavor.\\n\\n6. **Époisses**: A pungent, washed-rind cheese from Burgundy, known for its strong aroma and rich, creamy flavor.\\n\\n7. **Munster**: A soft, washed-rind cheese from the Alsace region, known for its strong smell and distinctive taste.\\n\\n8. **Beaufort**: A hard, alpine cheese made from raw cow\\'s milk, known for its smooth, nutty flavor and firm texture.\\n\\nEach of these cheeses has its own unique characteristics and is beloved for different reasons. The \"best\" one ultimately depends on your personal preferences.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response_mistralai(\"What is the best French cheese?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiagent workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain-anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "# os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "# os.environ[\"LANGCHAIN_API_KEY\"] = \"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\"\n",
    "# os.environ[\"LANGCHAIN_PROJECT\"] = \"nlp-project\"\n",
    "\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal, TypedDict\n",
    "\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import END, START, StateGraph, MessagesState\n",
    "from langgraph.prebuilt import ToolNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Based on the search results, I can tell you that the current weather in San Francisco is:\\n\\nTemperature: 60 degrees Fahrenheit\\nConditions: Foggy\\n\\nSan Francisco is known for its microclimates and frequent fog, especially during the summer months. The temperature of 60°F (about 15.5°C) is fairly typical for the city, which tends to have mild temperatures year-round.\\n\\nIs there anything else you'd like to know about the weather in San Francisco or any other location?\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Annotated, Literal, TypedDict\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import END, START, StateGraph, MessagesState\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "# Define the tools for the agent to use\n",
    "@tool\n",
    "def search(query: str):\n",
    "    \"\"\"Call to surf the web.\"\"\"\n",
    "    # This is a placeholder, but don't tell the LLM that...\n",
    "    if \"sf\" in query.lower() or \"san francisco\" in query.lower():\n",
    "        return \"It's 60 degrees and foggy.\"\n",
    "    return \"It's 90 degrees and sunny.\"\n",
    "\n",
    "tools = [search]\n",
    "\n",
    "model = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\", temperature=0).bind_tools(tools)\n",
    "\n",
    "# Define the function that determines whether to continue or not\n",
    "def should_continue(state: MessagesState) -> Literal[\"tools\", END]:\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1]\n",
    "    # If the LLM makes a tool call, then we route to the \"tools\" node\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    # Otherwise, we stop (reply to the user)\n",
    "    return END\n",
    "\n",
    "\n",
    "# Define the function that calls the model\n",
    "def call_model(state: MessagesState):\n",
    "    messages = state['messages']\n",
    "    response = model.invoke(messages)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "# Define the two nodes we will cycle between\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Set the entrypoint as `agent`\n",
    "# This means that this node is the first one called\n",
    "workflow.add_edge(START, \"agent\")\n",
    "\n",
    "# We now add a conditional edge\n",
    "workflow.add_conditional_edges(\n",
    "    # First, we define the start node. We use `agent`.\n",
    "    # This means these are the edges taken after the `agent` node is called.\n",
    "    \"agent\",\n",
    "    # Next, we pass in the function that will determine which node is called next.\n",
    "    should_continue,\n",
    ")\n",
    "\n",
    "# We now add a normal edge from `tools` to `agent`.\n",
    "# This means that after `tools` is called, `agent` node is called next.\n",
    "workflow.add_edge(\"tools\", 'agent')\n",
    "\n",
    "# Initialize memory to persist state between graph runs\n",
    "checkpointer = MemorySaver()\n",
    "\n",
    "# Finally, we compile it!\n",
    "# This compiles it into a LangChain Runnable,\n",
    "# meaning you can use it as you would any other runnable.\n",
    "# Note that we're (optionally) passing the memory when compiling the graph\n",
    "app = workflow.compile(checkpointer=checkpointer)\n",
    "\n",
    "# Use the Runnable\n",
    "final_state = app.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"what is the weather in sf\")]},\n",
    "    config={\"configurable\": {\"thread_id\": 42}}\n",
    ")\n",
    "final_state[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal, TypedDict\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import END, START, StateGraph, MessagesState\n",
    "from langgraph.prebuilt import ToolNode\n",
    "import random\n",
    "\n",
    "# Define the tool for answering questions\n",
    "@tool\n",
    "def answer_question(query: str):\n",
    "    \"\"\"Call to process and answer a multiple-choice question.\"\"\"\n",
    "    # Simulate processing of the query to determine the correct answer\n",
    "    if \"Карпатській операції\" in query:\n",
    "        return \"А\"\n",
    "    elif \"Горліцькому прориву\" in query:\n",
    "        return \"Б\"\n",
    "    elif \"Брусиловському прориву\" in query:\n",
    "        return \"В\"\n",
    "    elif \"Галицькій битві\" in query:\n",
    "        return \"Г\"\n",
    "    return random.choice([\"А\", \"Б\", \"В\", \"Г\", \"Д\"])  # Default if no match\n",
    "\n",
    "# Define a new tool for web search\n",
    "@tool\n",
    "def search_web(query: str):\n",
    "    \"\"\"Simulate a web search and return some random string.\"\"\"\n",
    "    return f\"Random web result for query: {query}\"\n",
    "\n",
    "# Define tools for the agent to use\n",
    "tools = [answer_question, search_web]\n",
    "\n",
    "# Define the language model and bind tools\n",
    "model = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\", temperature=0).bind_tools(tools)\n",
    "\n",
    "# Function to decide whether to use a tool or end\n",
    "\n",
    "def should_continue(state: MessagesState) -> Literal[\"tools\", END]:\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1]\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return END\n",
    "\n",
    "# Function that calls the model\n",
    "def call_model(state: MessagesState):\n",
    "    messages = state['messages']\n",
    "    response = model.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# Function to process the final response and return a letter with explanations\n",
    "def process_response(state: MessagesState):\n",
    "    last_message = state['messages'][-1]\n",
    "    # Extract only the letter and append explanations\n",
    "    answer = last_message.content.strip()[0]\n",
    "    explanations = f\"Based on additional context, the correct answer is {answer}.\"\n",
    "    return {\"messages\": [{\"role\": \"assistant\", \"content\": f\"{answer}, \\\"{explanations}\\\"\"}]}\n",
    "\n",
    "# Create the workflow\n",
    "graph = StateGraph(MessagesState)\n",
    "\n",
    "# Add nodes to the graph\n",
    "question_tool_node = ToolNode(tools)\n",
    "graph.add_node(\"agent\", call_model)\n",
    "graph.add_node(\"tools\", question_tool_node)\n",
    "graph.add_node(\"process\", process_response)\n",
    "\n",
    "graph.add_edge(START, \"agent\")\n",
    "graph.add_conditional_edges(\"agent\", should_continue)\n",
    "graph.add_edge(\"tools\", \"process\")\n",
    "\n",
    "# Initialize memory for persistence\n",
    "checkpointer = MemorySaver()\n",
    "\n",
    "# Compile the graph into a runnable app\n",
    "app = graph.compile(checkpointer=checkpointer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "А, \"Based on additional context, the correct answer is А.\"\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "final_state = app.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"Реалізація імперської стратегії Росії в Першій світовій війні щодо \\\"…злиття землі Ярослава Осмомисла, князів Данила і Романа з Імперією в політичному, соціальному та національному відношеннях…\\\" стала можливою завдяки\\n\\nА. Карпатській операції.\\nБ. Горліцькому прориву.\\nВ. Брусиловському прориву.\\nГ. Галицькій битві.\")],\n",
    "    },\n",
    "    config={\"configurable\": {\"thread_id\": 42}},\n",
    ")\n",
    "\n",
    "# Output the final answer\n",
    "print(final_state[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Any, Dict, List, Optional, Sequence, TypedDict\n",
    "\n",
    "from langchain_core.messages import HumanMessage, BaseMessage\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import END, START, StateGraph, MessagesState\n",
    "from langgraph.prebuilt import ToolNode\n",
    "import random\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "# from langchain_core.agents import AgentExecutor, create_anthropic_tools_agent\n",
    "# from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "import functools\n",
    "import operator\n",
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "\n",
    "@tool\n",
    "def search_web(query: str):\n",
    "    \"\"\"Simulate a web search and return some random string.\"\"\"\n",
    "    print(\"hello from search_web\")\n",
    "    return f\"Правильна відповідь на питання: А\"\n",
    "    return f\"Random web result for query: {query}\"\n",
    "\n",
    "@tool\n",
    "def search_in_dictionary(query: str):\n",
    "    \"\"\"Simulate a dictionary search and return some random string.\"\"\"\n",
    "    return f\"Random dictionary result for query: {query}\"\n",
    "\n",
    "@tool\n",
    "def retrieve_from_database(query: str):\n",
    "    \"\"\"Simulate a database query and return some random string.\"\"\"\n",
    "    return f\"Random database result for query: {query}\"\n",
    "\n",
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    return {\"messages\": [HumanMessage(content=result, name=name)]}\n",
    "\n",
    "# The agent state is the input to each node in the graph\n",
    "class AgentState(TypedDict):\n",
    "    # The annotation tells the graph that new messages will always be added to the current states\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    # The 'next' field indicates where to route to next\n",
    "    next: str\n",
    "\n",
    "# Create one agent for ukrainian language, literature and a separate for history\n",
    "# Ukrainian language and literature\n",
    "ukr_lit_tools = [search_web, search_in_dictionary]\n",
    "ukr_lit_agent = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\", temperature=0).bind_tools(ukr_lit_tools)\n",
    "ukr_lit_node = functools.partial(agent_node, agent=ukr_lit_agent, name=\"Ukrainian Language and Literature\")\n",
    "\n",
    "# History (use only search_web and retrieve_from_database)\n",
    "history_tools = [search_web, retrieve_from_database]\n",
    "history_agent = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\", temperature=0).bind_tools(history_tools)\n",
    "history_node = functools.partial(agent_node, agent=history_agent, name=\"History\")\n",
    "\n",
    "def call_model_history(state: AgentState):\n",
    "    messages = state['messages'][-1:]\n",
    "    print(messages)\n",
    "    response = history_agent.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def call_model_ukr_lit(state: AgentState):\n",
    "    messages = state['messages']\n",
    "    response = ukr_lit_agent.invoke(messages)\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='Реалізація імперської стратегії Росії в Першій світовій війні щодо \"…злиття землі Ярослава Осмомисла, князів Данила і Романа з Імперією в політичному, соціальному та національному відношеннях…\" стала можливою завдяки\\n\\nА. Карпатській операції.\\nБ. Горліцькому прориву.\\nВ. Брусиловському прориву.\\nГ. Галицькій битві.', additional_kwargs={}, response_metadata={})]\n",
      "{'role': 'assistant', 'content': 'R, \"Based on additional context, the correct answer is R.\"'}\n"
     ]
    }
   ],
   "source": [
    "def call_model_history(state: AgentState):\n",
    "    messages = state['messages']\n",
    "    print(messages)\n",
    "    response = history_agent.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def should_continue(state: AgentState) -> Literal[\"tools\", END]:\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1]\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return END\n",
    "\n",
    "# Function to process the final response and return a letter with explanations\n",
    "def process_response(state: AgentState):\n",
    "    last_message = state['messages'][-1]\n",
    "    # Extract only the letter and append explanations\n",
    "    answer = last_message.content.strip()[0]\n",
    "    explanations = f\"Based on additional context, the correct answer is {answer}.\"\n",
    "    return {\"messages\": [{\"role\": \"assistant\", \"content\": f\"{answer}, \\\"{explanations}\\\"\"}]}\n",
    "\n",
    "# Create the workflow\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "# Add nodes to the graph\n",
    "question_tool_node = ToolNode(history_tools)\n",
    "graph.add_node(\"agent\", call_model_history)\n",
    "graph.add_node(\"tools\", question_tool_node)\n",
    "graph.add_node(\"process\", process_response)\n",
    "\n",
    "graph.add_edge(START, \"agent\")\n",
    "graph.add_conditional_edges(\"agent\", should_continue)\n",
    "graph.add_edge(\"tools\", \"process\")\n",
    "\n",
    "# Initialize memory for persistence\n",
    "checkpointer = MemorySaver()\n",
    "\n",
    "# Compile the graph into a runnable app\n",
    "app = graph.compile(checkpointer=checkpointer)\n",
    "\n",
    "# Example usage\n",
    "final_state = app.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"Реалізація імперської стратегії Росії в Першій світовій війні щодо \\\"…злиття землі Ярослава Осмомисла, князів Данила і Романа з Імперією в політичному, соціальному та національному відношеннях…\\\" стала можливою завдяки\\n\\nА. Карпатській операції.\\nБ. Горліцькому прориву.\\nВ. Брусиловському прориву.\\nГ. Галицькій битві.\")],\n",
    "    },\n",
    "    config={\"configurable\": {\"thread_id\": 42}},\n",
    ")\n",
    "\n",
    "# Output the final answer\n",
    "print(final_state[\"messages\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the main agent that will decide which agent to use\n",
    "members = [\"Ukrainian Language and Literature\", \"History\"]\n",
    "system_prompt = (\n",
    "    \"Ти наглядач команди з {members}. На основі запиту від користувача обери підходящого члена команди і поверни його. Кожен член команди виконає завдання і повернеться з результатами та статусом. Коли закінчиш, поверни FINISH.\"\n",
    ")\n",
    "options = [\"FINISH\"] + members\n",
    "\n",
    "function_def = {\n",
    "    \"name\": \"route\",\n",
    "    \"description\": \"Select the next role.\",\n",
    "    \"parameters\": {\n",
    "        \"title\": \"routeSchema\",\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"next\": {\n",
    "                \"title\": \"Next\",\n",
    "                \"anyOf\": [\n",
    "                    {\"enum\": options},\n",
    "                ],\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"next\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "# Define the prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Given the conversation above, who would act next? Or should we FINISH? Select one of: {options}.\",\n",
    "        ),\n",
    "    ]\n",
    ").partial(options=str(options), members=\", \".join(members))\n",
    "\n",
    "def bind_functions(llm: ChatAnthropic, prompt: ChatPromptTemplate, functions: Dict, function_call: str):\n",
    "    def process_prompt(messages: List[Dict[str, str]]):\n",
    "        print(messages[\"messages\"][0])\n",
    "        # formatted_messages = [{\"role\": message[\"role\"], \"content\": message[\"content\"]} for message in messages]\n",
    "        formatted_messages = [{\"role\": \"user\", \"content\": messages[\"messages\"][i].content} for i in range(len(messages[\"messages\"]))]\n",
    "        print(formatted_messages)\n",
    "        full_prompt = prompt.format(messages=formatted_messages)\n",
    "        response = llm.predict(full_prompt)\n",
    "        if \"History\" in response:\n",
    "            return {\"next\": \"History\"}\n",
    "        if \"Ukrainian Language and Literature\" in response or \"language\" in response or \"literature\" in response:\n",
    "            return {\"next\": \"Ukrainian Language and Literature\"}\n",
    "        return {\"next\": \"FINISH\"}\n",
    "    return process_prompt\n",
    "\n",
    "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\", temperature=0)\n",
    "supervisor_chain = bind_functions(llm, prompt, functions=[function_def], function_call=\"route\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Please analyze the literature context.\"}\n",
    "]\n",
    "output = supervisor_chain(messages)\n",
    "print(f\"Next action: {output}\")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Please analyze the histrory context.\"}\n",
    "]\n",
    "output = supervisor_chain(messages)\n",
    "print(f\"Next action: {output}\")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"That's it.\"}\n",
    "]\n",
    "output = supervisor_chain(messages)\n",
    "print(f\"Next action: {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Реалізація імперської стратегії Росії в Першій світовій війні щодо «…злиття землі Ярослава Осмомисла, князів Данила і Романа з Імперією в політичному, соціальному та національному відношеннях…» стала можливою завдяки\\nА. Карпатській операції.\\nБ. Горліцькому прориву.\\nВ. Брусиловському прориву.\\nГ. Галицькій битві.' additional_kwargs={} response_metadata={}\n",
      "[{'role': 'user', 'content': 'Реалізація імперської стратегії Росії в Першій світовій війні щодо «…злиття землі Ярослава Осмомисла, князів Данила і Романа з Імперією в політичному, соціальному та національному відношеннях…» стала можливою завдяки\\nА. Карпатській операції.\\nБ. Горліцькому прориву.\\nВ. Брусиловському прориву.\\nГ. Галицькій битві.'}]\n",
      "[HumanMessage(content='Реалізація імперської стратегії Росії в Першій світовій війні щодо «…злиття землі Ярослава Осмомисла, князів Данила і Романа з Імперією в політичному, соціальному та національному відношеннях…» стала можливою завдяки\\nА. Карпатській операції.\\nБ. Горліцькому прориву.\\nВ. Брусиловському прориву.\\nГ. Галицькій битві.', additional_kwargs={}, response_metadata={})]\n",
      "content='Реалізація імперської стратегії Росії в Першій світовій війні щодо «…злиття землі Ярослава Осмомисла, князів Данила і Романа з Імперією в політичному, соціальному та національному відношеннях…» стала можливою завдяки\\nА. Карпатській операції.\\nБ. Горліцькому прориву.\\nВ. Брусиловському прориву.\\nГ. Галицькій битві.' additional_kwargs={} response_metadata={}\n",
      "[{'role': 'user', 'content': [{'text': 'Для того, щоб правильно відповісти на це запитання, нам потрібно дослідити історичні події Першої світової війни, зокрема ті, що стосуються російської імперської стратегії щодо українських земель. Давайте використаємо доступні інструменти для пошуку необхідної інформації.', 'type': 'text'}, {'id': 'toolu_011usWR915CMEjySZuNAJRJt', 'input': {'query': 'Російська імперська стратегія в Першій світовій війні щодо українських земель'}, 'name': 'search_web', 'type': 'tool_use'}]}]\n",
      "hello from search_web\n",
      "[ToolMessage(content='Правильна відповідь на питання: А', name='search_web', tool_call_id='toolu_011usWR915CMEjySZuNAJRJt')]\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'messages.0: `tool_result` block(s) provided when previous message does not contain any `tool_use` blocks'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[168], line 28\u001b[0m\n\u001b[0;32m     20\u001b[0m graph \u001b[38;5;241m=\u001b[39m workflow\u001b[38;5;241m.\u001b[39mcompile()\n\u001b[0;32m     22\u001b[0m question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mРеалізація імперської стратегії Росії в Першій світовій війні щодо «…злиття землі Ярослава Осмомисла, князів Данила і Романа з Імперією в політичному, соціальному та національному відношеннях…» стала можливою завдяки\u001b[39m\u001b[38;5;124m\"\u001b[39m\\\n\u001b[0;32m     23\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mА. Карпатській операції.\u001b[39m\u001b[38;5;124m\"\u001b[39m\\\n\u001b[0;32m     24\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mБ. Горліцькому прориву.\u001b[39m\u001b[38;5;124m\"\u001b[39m\\\n\u001b[0;32m     25\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mВ. Брусиловському прориву.\u001b[39m\u001b[38;5;124m\"\u001b[39m\\\n\u001b[0;32m     26\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mГ. Галицькій битві.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 28\u001b[0m final_state \u001b[38;5;241m=\u001b[39m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfigurable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthread_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(final_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mcontent)\n",
      "File \u001b[1;32mc:\\Users\\famil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langgraph\\pregel\\__init__.py:1927\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1926\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 1927\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[0;32m   1928\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   1929\u001b[0m     config,\n\u001b[0;32m   1930\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39mstream_mode,\n\u001b[0;32m   1931\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[0;32m   1932\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[0;32m   1933\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[0;32m   1934\u001b[0m     debug\u001b[38;5;241m=\u001b[39mdebug,\n\u001b[0;32m   1935\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1936\u001b[0m ):\n\u001b[0;32m   1937\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1938\u001b[0m         latest \u001b[38;5;241m=\u001b[39m chunk\n",
      "File \u001b[1;32mc:\\Users\\famil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langgraph\\pregel\\__init__.py:1647\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[0;32m   1641\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[0;32m   1642\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[0;32m   1643\u001b[0m     \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[0;32m   1644\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[0;32m   1645\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[0;32m   1646\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[1;32m-> 1647\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[0;32m   1648\u001b[0m             loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[0;32m   1649\u001b[0m             timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[0;32m   1650\u001b[0m             retry_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policy,\n\u001b[0;32m   1651\u001b[0m             get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[0;32m   1652\u001b[0m         ):\n\u001b[0;32m   1653\u001b[0m             \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m output()\n\u001b[0;32m   1655\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\famil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langgraph\\pregel\\runner.py:104\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[0;32m    102\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 104\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\famil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, writer)\u001b[0m\n\u001b[0;32m     38\u001b[0m task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# if successful, end\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\famil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langgraph\\utils\\runnable.py:410\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    408\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 410\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    411\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    412\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mc:\\Users\\famil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langgraph\\utils\\runnable.py:184\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    183\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m--> 184\u001b[0m     ret \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, \u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[1;32mIn[165], line 60\u001b[0m, in \u001b[0;36mcall_model_history\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m     58\u001b[0m messages \u001b[38;5;241m=\u001b[39m state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(messages)\n\u001b[1;32m---> 60\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mhistory_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [response]}\n",
      "File \u001b[1;32mc:\\Users\\famil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_core\\runnables\\base.py:5354\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   5348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m   5349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5350\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[0;32m   5351\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   5352\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   5353\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[1;32m-> 5354\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbound\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[0;32m   5355\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   5356\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_configs(config),\n\u001b[0;32m   5357\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs},\n\u001b[0;32m   5358\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\famil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:286\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    282\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m    283\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    285\u001b[0m         ChatGeneration,\n\u001b[1;32m--> 286\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    287\u001b[0m             [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[0;32m    288\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    289\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    290\u001b[0m             tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    291\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    292\u001b[0m             run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    293\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    294\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    295\u001b[0m         )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    296\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32mc:\\Users\\famil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:786\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    779\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    780\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    784\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    785\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\famil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:643\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[0;32m    642\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[1;32m--> 643\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    644\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    645\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[0;32m    646\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[0;32m    647\u001b[0m ]\n\u001b[0;32m    648\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[1;32mc:\\Users\\famil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:633\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 633\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    634\u001b[0m                 m,\n\u001b[0;32m    635\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    636\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    637\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    638\u001b[0m             )\n\u001b[0;32m    639\u001b[0m         )\n\u001b[0;32m    640\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    641\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mc:\\Users\\famil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:851\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    850\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 851\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m    852\u001b[0m             messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    853\u001b[0m         )\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    855\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\famil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_anthropic\\chat_models.py:796\u001b[0m, in \u001b[0;36mChatAnthropic._generate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    794\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m generate_from_stream(stream_iter)\n\u001b[0;32m    795\u001b[0m payload \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_request_payload(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 796\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mmessages\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpayload)\n\u001b[0;32m    797\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_output(data, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\famil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\anthropic\\_utils\\_utils.py:275\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    273\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\famil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\anthropic\\resources\\messages.py:888\u001b[0m, in \u001b[0;36mMessages.create\u001b[1;34m(self, max_tokens, messages, model, metadata, stop_sequences, stream, system, temperature, tool_choice, tools, top_k, top_p, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m DEPRECATED_MODELS:\n\u001b[0;32m    882\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    883\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe model \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is deprecated and will reach end-of-life on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDEPRECATED_MODELS[model]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPlease migrate to a newer model. Visit https://docs.anthropic.com/en/docs/resources/model-deprecations for more information.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    884\u001b[0m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[0;32m    885\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m    886\u001b[0m     )\n\u001b[1;32m--> 888\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/v1/messages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    892\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    895\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    896\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop_sequences\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop_sequences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    897\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    898\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    899\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    901\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_k\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    903\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    904\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    905\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessage_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMessageCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    906\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    907\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    908\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    909\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    910\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMessage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    911\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    912\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mRawMessageStreamEvent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    913\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\famil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\anthropic\\_base_client.py:1279\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1265\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1266\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1267\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1274\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1275\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1276\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1277\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1278\u001b[0m     )\n\u001b[1;32m-> 1279\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\famil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\anthropic\\_base_client.py:956\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    954\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\famil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\anthropic\\_base_client.py:1060\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1057\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1059\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1060\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1063\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1064\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1068\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m   1069\u001b[0m )\n",
      "\u001b[1;31mBadRequestError\u001b[0m: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'messages.0: `tool_result` block(s) provided when previous message does not contain any `tool_use` blocks'}}"
     ]
    }
   ],
   "source": [
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"History\", call_model_history)\n",
    "workflow.add_node(\"Ukrainian Language and Literature\", call_model_ukr_lit)\n",
    "workflow.add_node(\"supervisor\", supervisor_chain)\n",
    "history_tool_node = ToolNode(history_tools)\n",
    "workflow.add_node(\"history_tools\", history_tool_node)\n",
    "\n",
    "for member in members:\n",
    "    workflow.add_edge(member, \"supervisor\")\n",
    "\n",
    "conditional_map = {k: k for k in members}\n",
    "conditional_map[\"FINISH\"] = END\n",
    "workflow.add_conditional_edges(\"supervisor\", lambda x: x[\"next\"], conditional_map)\n",
    "\n",
    "workflow.add_edge(\"History\", \"history_tools\")\n",
    "workflow.add_edge(\"history_tools\", \"History\")\n",
    "\n",
    "workflow.set_entry_point(\"supervisor\")\n",
    "\n",
    "graph = workflow.compile()\n",
    "\n",
    "question = \"Реалізація імперської стратегії Росії в Першій світовій війні щодо «…злиття землі Ярослава Осмомисла, князів Данила і Романа з Імперією в політичному, соціальному та національному відношеннях…» стала можливою завдяки\"\\\n",
    "\"\\nА. Карпатській операції.\"\\\n",
    "\"\\nБ. Горліцькому прориву.\"\\\n",
    "\"\\nВ. Брусиловському прориву.\"\\\n",
    "\"\\nГ. Галицькій битві.\"\n",
    "\n",
    "final_state = graph.invoke(\n",
    "    {\"messages\": [HumanMessage(content=question)]},\n",
    "    config={\"configurable\": {\"thread_id\": 42}},\n",
    ")\n",
    "\n",
    "print(final_state[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\famil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.3.9)\n",
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.2.11-py3-none-any.whl (50 kB)\n",
      "     ---------------------------------------- 0.0/50.7 kB ? eta -:--:--\n",
      "     ------------------------------ ------- 41.0/50.7 kB 991.0 kB/s eta 0:00:01\n",
      "     -------------------------------------- 50.7/50.7 kB 652.0 kB/s eta 0:00:00\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in c:\\users\\famil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (0.3.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\famil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\famil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (0.1.147)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\famil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\famil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (3.11.8)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in c:\\users\\famil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (1.24.3)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\famil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.21 in c:\\users\\famil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (0.3.21)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\famil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (9.0.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\famil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (2.0.30)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\famil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (2.10.2)\n",
      "Collecting openai<2.0.0,>=1.54.0\n",
      "  Downloading openai-1.57.0-py3-none-any.whl (389 kB)\n",
      "     ---------------------------------------- 0.0/389.9 kB ? eta -:--:--\n",
      "     ------ -------------------------------- 61.4/389.9 kB 1.1 MB/s eta 0:00:01\n",
      "     ------------- ------------------------ 143.4/389.9 kB 1.4 MB/s eta 0:00:01\n",
      "     --------------------- ---------------- 225.3/389.9 kB 2.0 MB/s eta 0:00:01\n",
      "     ----------------------------- -------- 307.2/389.9 kB 1.6 MB/s eta 0:00:01\n",
      "     -------------------------------------  389.1/389.9 kB 1.7 MB/s eta 0:00:01\n",
      "     -------------------------------------- 389.9/389.9 kB 1.6 MB/s eta 0:00:00\n",
      "Collecting tiktoken<1,>=0.7\n",
      "  Downloading tiktoken-0.8.0-cp310-cp310-win_amd64.whl (884 kB)\n",
      "     ---------------------------------------- 0.0/884.2 kB ? eta -:--:--\n",
      "     ------- ------------------------------ 174.1/884.2 kB 5.3 MB/s eta 0:00:01\n",
      "     -------------- ----------------------- 337.9/884.2 kB 3.5 MB/s eta 0:00:01\n",
      "     ------------------ ------------------- 440.3/884.2 kB 3.4 MB/s eta 0:00:01\n",
      "     ---------------------- --------------- 532.5/884.2 kB 2.8 MB/s eta 0:00:01\n",
      "     ---------------------------- --------- 665.6/884.2 kB 3.0 MB/s eta 0:00:01\n",
      "     -------------------------------------  880.6/884.2 kB 3.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- 884.2/884.2 kB 2.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\famil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\famil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\famil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\famil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\famil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\famil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\famil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\famil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.21->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\famil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.21->langchain) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\famil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.21->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\famil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\famil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.6)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\famil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\famil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai<2.0.0,>=1.54.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\famil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai<2.0.0,>=1.54.0->langchain-openai) (4.3.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\famil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai<2.0.0,>=1.54.0->langchain-openai) (0.8.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\famil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai<2.0.0,>=1.54.0->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\famil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai<2.0.0,>=1.54.0->langchain-openai) (4.66.4)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\famil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\famil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\famil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\famil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\famil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\famil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\famil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\famil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.7.24)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\famil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.54.0->langchain-openai) (1.2.1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\famil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\famil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\famil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.21->langchain) (3.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\famil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.54.0->langchain-openai) (0.4.6)\n",
      "Installing collected packages: tiktoken, openai, langchain-openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.37.1\n",
      "    Uninstalling openai-1.37.1:\n",
      "      Successfully uninstalled openai-1.37.1\n",
      "Successfully installed langchain-openai-0.2.11 openai-1.57.0 tiktoken-0.8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HumanMessage(content='output', additional_kwargs={}, response_metadata={}, name='History')"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HumanMessage(content=\"output\", name=\"History\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's start from scratch\n",
    "\n",
    "thanks for tools tutorial: https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#using-with-chat-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal, TypedDict\n",
    "\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import END, START, StateGraph, MessagesState\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_weather(location: str):\n",
    "    \"\"\"Call to get the current weather.\"\"\"\n",
    "    if location.lower() in [\"sf\", \"san francisco\"]:\n",
    "        return \"It's 60 degrees and foggy.\"\n",
    "    else:\n",
    "        return \"It's 90 degrees and sunny.\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_coolest_cities():\n",
    "    \"\"\"Get a list of coolest cities\"\"\"\n",
    "    return \"nyc, sf\"\n",
    "\n",
    "tools = [get_weather, get_coolest_cities]\n",
    "tool_node = ToolNode(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [ToolMessage(content=\"It's 60 degrees and foggy.\", name='get_weather', tool_call_id='tool_call_id')]}"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_with_single_tool_call = AIMessage(\n",
    "    content=\"\",\n",
    "    tool_calls=[\n",
    "        {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"args\": {\"location\": \"sf\"},\n",
    "            \"id\": \"tool_call_id\",\n",
    "            \"type\": \"tool_call\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "tool_node.invoke({\"messages\": [message_with_single_tool_call]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [ToolMessage(content='nyc, sf', name='get_coolest_cities', tool_call_id='tool_call_id_1'),\n",
       "  ToolMessage(content=\"It's 60 degrees and foggy.\", name='get_weather', tool_call_id='tool_call_id_2')]}"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_with_multiple_tool_calls = AIMessage(\n",
    "    content=\"\",\n",
    "    tool_calls=[\n",
    "        {\n",
    "            \"name\": \"get_coolest_cities\",\n",
    "            \"args\": {},\n",
    "            \"id\": \"tool_call_id_1\",\n",
    "            \"type\": \"tool_call\",\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"args\": {\"location\": \"sf\"},\n",
    "            \"id\": \"tool_call_id_2\",\n",
    "            \"type\": \"tool_call\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "tool_node.invoke({\"messages\": [message_with_multiple_tool_calls]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_tools = ChatAnthropic(\n",
    "    model=\"claude-3-haiku-20240307\", temperature=0\n",
    ").bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=[{'text': \"Okay, let's find the weather in San Francisco and the coolest city:\", 'type': 'text'}, {'id': 'toolu_01CwEUSmdvrD4DnMz1tWRQLT', 'input': {'location': 'San Francisco'}, 'name': 'get_weather', 'type': 'tool_use'}], additional_kwargs={}, response_metadata={'id': 'msg_01TJuVA3kzfphd2cc5Urvtvt', 'model': 'claude-3-haiku-20240307', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'input_tokens': 383, 'output_tokens': 72}}, id='run-69060e27-f459-4b08-a04c-d7d7ba8ff702-0', tool_calls=[{'name': 'get_weather', 'args': {'location': 'San Francisco'}, 'id': 'toolu_01CwEUSmdvrD4DnMz1tWRQLT', 'type': 'tool_call'}], usage_metadata={'input_tokens': 383, 'output_tokens': 72, 'total_tokens': 455, 'input_token_details': {}})"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = model_with_tools.invoke(\"what is the weather in sf and what is the coolest city?\")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': \"Okay, let's find the weather in San Francisco and the coolest city:\",\n",
       "  'type': 'text'},\n",
       " {'id': 'toolu_01CwEUSmdvrD4DnMz1tWRQLT',\n",
       "  'input': {'location': 'San Francisco'},\n",
       "  'name': 'get_weather',\n",
       "  'type': 'tool_use'}]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'get_weather',\n",
       "  'args': {'location': 'San Francisco'},\n",
       "  'id': 'toolu_01CwEUSmdvrD4DnMz1tWRQLT',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [ToolMessage(content=\"It's 60 degrees and foggy.\", name='get_weather', tool_call_id='toolu_011vwLH2Wv2bhkQKwaNmJeRf')]}"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_node.invoke({\"messages\": [model_with_tools.invoke(\"what's the weather in sf?\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state: MessagesState):\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return END\n",
    "\n",
    "\n",
    "def call_model(state: MessagesState):\n",
    "    messages = state[\"messages\"]\n",
    "    response = model_with_tools.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "# Define the two nodes we will cycle between\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "workflow.add_edge(START, \"agent\")\n",
    "workflow.add_conditional_edges(\"agent\", should_continue, [\"tools\", END])\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(app.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "what's the weather in sf?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"Okay, let's check the weather in San Francisco:\", 'type': 'text'}, {'id': 'toolu_012Lw2VjZAWXfS88NUgosj6r', 'input': {'location': 'San Francisco'}, 'name': 'get_weather', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  get_weather (toolu_012Lw2VjZAWXfS88NUgosj6r)\n",
      " Call ID: toolu_012Lw2VjZAWXfS88NUgosj6r\n",
      "  Args:\n",
      "    location: San Francisco\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_weather\n",
      "\n",
      "It's 60 degrees and foggy.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The weather in San Francisco is currently 60 degrees with foggy conditions.\n"
     ]
    }
   ],
   "source": [
    "# example with a single tool call\n",
    "\n",
    "for chunk in app.stream(\n",
    "    {\"messages\": [(\"human\", \"what's the weather in sf?\")]}, stream_mode=\"values\"\n",
    "):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "what's the weather in the coolest cities?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"Okay, let's find out the weather in the coolest cities:\", 'type': 'text'}, {'id': 'toolu_01K8o8bgG2PuNvMtMdBVqCQt', 'input': {}, 'name': 'get_coolest_cities', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  get_coolest_cities (toolu_01K8o8bgG2PuNvMtMdBVqCQt)\n",
      " Call ID: toolu_01K8o8bgG2PuNvMtMdBVqCQt\n",
      "  Args:\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_coolest_cities\n",
      "\n",
      "nyc, sf\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"Now let's get the weather for those cities:\", 'type': 'text'}, {'id': 'toolu_01N217JXXmxiRYDhDvLY8SPo', 'input': {'location': 'nyc'}, 'name': 'get_weather', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  get_weather (toolu_01N217JXXmxiRYDhDvLY8SPo)\n",
      " Call ID: toolu_01N217JXXmxiRYDhDvLY8SPo\n",
      "  Args:\n",
      "    location: nyc\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_weather\n",
      "\n",
      "It's 90 degrees and sunny.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'id': 'toolu_01DryzRDRbKd2dJ3xfnzM5Sv', 'input': {'location': 'sf'}, 'name': 'get_weather', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  get_weather (toolu_01DryzRDRbKd2dJ3xfnzM5Sv)\n",
      " Call ID: toolu_01DryzRDRbKd2dJ3xfnzM5Sv\n",
      "  Args:\n",
      "    location: sf\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_weather\n",
      "\n",
      "It's 60 degrees and foggy.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Based on the results, it looks like the weather in the coolest cities is:\n",
      "- New York City: 90 degrees and sunny\n",
      "- San Francisco: 60 degrees and foggy\n",
      "\n",
      "So the weather in the coolest cities is a mix of warm and cool temperatures, with some sunny and some foggy conditions.\n"
     ]
    }
   ],
   "source": [
    "# example with a multiple tool calls in succession\n",
    "\n",
    "for chunk in app.stream(\n",
    "    {\"messages\": [(\"human\", \"what's the weather in the coolest cities?\")]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent with math and weather tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mathematical tools\n",
    "\n",
    "@tool\n",
    "def add_numbers(a: int, b: int):\n",
    "    \"\"\"AIMessage tool to add two numbers.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def is_even(number: int):\n",
    "    \"\"\"AIMessage tool to check if a number is even.\"\"\"\n",
    "    return number % 2 == 0\n",
    "\n",
    "tools = [add_numbers, is_even]\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "model_with_tools = ChatAnthropic(\n",
    "    model=\"claude-3-haiku-20240307\", temperature=0\n",
    ").bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def should_continue(state: MessagesState):\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    if last_message.tool_calls:\n",
    "        return \"math_tools\"\n",
    "    return END\n",
    "\n",
    "\n",
    "def call_model(state: MessagesState):\n",
    "    messages = state[\"messages\"]\n",
    "    response = model_with_tools.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "# Define the two nodes we will cycle between\n",
    "workflow.add_node(\"math_agent\", call_model)\n",
    "workflow.add_node(\"math_tools\", tool_node)\n",
    "\n",
    "workflow.add_edge(START, \"math_agent\")\n",
    "workflow.add_conditional_edges(\"math_agent\", should_continue, [\"math_tools\", END])\n",
    "workflow.add_edge(\"math_tools\", \"math_agent\")\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "try:\n",
    "    display(Image(app.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "what's the weather in sf?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I'm afraid I don't have the capability to check the weather in San Francisco. As an AI assistant without direct access to weather data, I don't have a way to look up and report the current weather conditions in a specific location. I can only respond based on the tools and information I've been provided. If you need to check the weather forecast, I'd suggest using a weather app or website that can provide that information directly.\n"
     ]
    }
   ],
   "source": [
    "for chunk in app.stream(\n",
    "    {\"messages\": [(\"human\", \"what's the weather in sf?\")]}, stream_mode=\"values\"\n",
    "):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "is 7 even?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"Okay, let's check if 7 is an even number:\", 'type': 'text'}, {'id': 'toolu_014HccbFFSetFN1j6bazySnG', 'input': {'number': 7}, 'name': 'is_even', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  is_even (toolu_014HccbFFSetFN1j6bazySnG)\n",
      " Call ID: toolu_014HccbFFSetFN1j6bazySnG\n",
      "  Args:\n",
      "    number: 7\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: is_even\n",
      "\n",
      "false\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result shows that 7 is not an even number, it is an odd number.\n"
     ]
    }
   ],
   "source": [
    "for chunk in app.stream(\n",
    "    {\"messages\": [(\"human\", \"is 7 even?\")]}, stream_mode=\"values\"\n",
    "):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weather_tools = [get_weather, get_coolest_cities]\n",
    "weather_tool_node = ToolNode(weather_tools)\n",
    "\n",
    "math_tools = [add_numbers, is_even]\n",
    "math_tool_node = ToolNode(math_tools)\n",
    "\n",
    "model_with_tools = ChatAnthropic(model=\"claude-3-haiku-20240307\", temperature=0).bind_tools(weather_tools + math_tools)\n",
    "\n",
    "def should_continue(state: MessagesState):\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    if last_message.tool_calls:\n",
    "        if last_message.tool_calls[0][\"name\"] in [\"get_weather\", \"get_coolest_cities\"]:\n",
    "            return \"weather_tools\"\n",
    "        if last_message.tool_calls[0][\"name\"] in [\"add_numbers\", \"is_even\"]:\n",
    "            return \"math_tools\"\n",
    "    return END\n",
    "\n",
    "def call_model(state: MessagesState):\n",
    "    messages = state[\"messages\"]\n",
    "    response = model_with_tools.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "# Define the two nodes we will cycle between\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"weather_tools\", weather_tool_node)\n",
    "workflow.add_node(\"math_tools\", math_tool_node)\n",
    "\n",
    "workflow.add_edge(START, \"agent\")\n",
    "\n",
    "workflow.add_conditional_edges(\"agent\", should_continue, [\"math_tools\", \"weather_tools\", END])\n",
    "workflow.add_edge(\"weather_tools\", \"agent\")\n",
    "workflow.add_edge(\"math_tools\", \"agent\")\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "try:\n",
    "    display(Image(app.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "is the number of people in the coolest city even?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"Okay, let's check if the number of people in the coolest city is even.\", 'type': 'text'}, {'id': 'toolu_01XBMsR1vc1FrJKzcS9DoHp6', 'input': {}, 'name': 'get_coolest_cities', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  get_coolest_cities (toolu_01XBMsR1vc1FrJKzcS9DoHp6)\n",
      " Call ID: toolu_01XBMsR1vc1FrJKzcS9DoHp6\n",
      "  Args:\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_coolest_cities\n",
      "\n",
      "nyc, sf\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"Let's get the population of the first city in the list, which is New York City (NYC).\", 'type': 'text'}, {'id': 'toolu_01722zFgoRCmpGhZ6Bqibxiu', 'input': {'location': 'nyc'}, 'name': 'get_weather', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  get_weather (toolu_01722zFgoRCmpGhZ6Bqibxiu)\n",
      " Call ID: toolu_01722zFgoRCmpGhZ6Bqibxiu\n",
      "  Args:\n",
      "    location: nyc\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_weather\n",
      "\n",
      "It's 90 degrees and sunny.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"The weather data doesn't include the population, so let's use a different tool to check if the population is even.\", 'type': 'text'}, {'id': 'toolu_01R4YcoFWmxEBwX1ZamsBYP5', 'input': {'number': 8804190}, 'name': 'is_even', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  is_even (toolu_01R4YcoFWmxEBwX1ZamsBYP5)\n",
      " Call ID: toolu_01R4YcoFWmxEBwX1ZamsBYP5\n",
      "  Args:\n",
      "    number: 8804190\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: is_even\n",
      "\n",
      "true\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The population of NYC, which is the coolest city, is 8,804,190, which is an even number. Therefore, the answer is yes, the number of people in the coolest city is even.\n"
     ]
    }
   ],
   "source": [
    "for chunk in app.stream(\n",
    "    {\"messages\": [(\"human\", \"is the number of people in the coolest city even?\")]}, stream_mode=\"values\"\n",
    "):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
